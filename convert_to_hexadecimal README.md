This code converts a decimal integer to its hexadecimal string representation. It uses an `unsigned int` to correctly handle negative numbers by preserving their binary bit pattern. It repeatedly takes `num % 16` to extract each hex digit from least to most significant. The digits are mapped using a hex lookup string and prepended to the result. The time complexity is O(log₁₆(num)) ≈ O(1) for 32-bit integers, and space complexity is O(1).
